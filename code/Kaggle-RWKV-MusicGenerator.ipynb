{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/SudharshanShanmugasundaram/Music-Generation.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport os\nimport sys\nimport random\nsys.path.append('./Music-Generation/midi')\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.utils.data as data","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:20:43.948987Z","start_time":"2018-11-27T12:20:30.225783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls Music-Generation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from midi_utils import midiread, midiwrite\nfrom matplotlib import pyplot as plt\nimport skimage.io as io\nfrom IPython.display import FileLink\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:20:52.800756Z","start_time":"2018-11-27T12:20:43.965495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.utils.data as data\n\n\ndef midi_filename_to_piano_roll(midi_filename):\n    \n    midi_data = midiread(midi_filename, dt=0.3)\n    \n    piano_roll = midi_data.piano_roll.transpose()\n    \n    # Pressed notes are replaced by 1\n    piano_roll[piano_roll > 0] = 1\n    \n    return piano_roll\n\n\ndef pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n        \n    original_piano_roll_length = piano_roll.shape[1]\n    \n    padded_piano_roll = np.zeros((88, max_length))\n    padded_piano_roll[:] = pad_value\n    \n    padded_piano_roll[:, -original_piano_roll_length:] = piano_roll\n\n    return padded_piano_roll\n\n\nclass NotesGenerationDataset(data.Dataset):\n    \n    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n        \n        self.midi_folder_path = midi_folder_path\n        \n        midi_filenames = os.listdir(midi_folder_path)\n        \n        self.longest_sequence_length = longest_sequence_length\n        \n        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),midi_filenames)\n        \n        self.midi_full_filenames = list(midi_full_filenames)\n        \n        if longest_sequence_length is None:\n            \n            self.update_the_max_length()\n    \n    \n    def update_the_max_length(self):\n        \n        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],self.midi_full_filenames)\n        \n        max_length = max(sequences_lengths)\n        \n        self.longest_sequence_length = max_length\n                \n    \n    def __len__(self):\n        \n        return len(self.midi_full_filenames)\n    \n    def __getitem__(self, index):\n        \n        midi_full_filename = self.midi_full_filenames[index]\n        \n        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n        \n        # Shifting by one time step\n        sequence_length = piano_roll.shape[1] - 1\n        \n        # Shifting by one time step\n        input_sequence = piano_roll[:, :-1]\n        ground_truth_sequence = piano_roll[:, 1:]\n                \n        # padding sequence so that all of them have the same length\n        input_sequence_padded = pad_piano_roll(input_sequence, max_length=self.longest_sequence_length)\n        \n        ground_truth_sequence_padded = pad_piano_roll(ground_truth_sequence,max_length=self.longest_sequence_length,pad_value=-100)\n                \n        input_sequence_padded = input_sequence_padded.transpose()\n        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n        \n        return (torch.FloatTensor(input_sequence_padded),torch.LongTensor(ground_truth_sequence_padded),torch.LongTensor([sequence_length]) )\n\n    \ndef post_process_sequence_batch(batch_tuple):\n    \n    input_sequences, output_sequences, lengths = batch_tuple\n    \n    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n    splitted_lengths_batch = lengths.split(split_size=1)\n\n    training_data_tuples = zip(splitted_input_sequence_batch,\n                               splitted_output_sequence_batch,\n                               splitted_lengths_batch)\n\n    training_data_tuples_sorted = sorted(training_data_tuples,\n                                         key=lambda p: int(p[2]),\n                                         reverse=True)\n\n    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n\n    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n    \n    input_sequence_batch_sorted = input_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n    output_sequence_batch_sorted = output_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n    \n    input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n    \n    lengths_batch_sorted_list = list(lengths_batch_sorted)\n    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n    \n    return input_sequence_batch_transposed, output_sequence_batch_sorted, list(lengths_batch_sorted_list)","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:20:52.867674Z","start_time":"2018-11-27T12:20:52.819795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset = NotesGenerationDataset('./Music-Generation/notebooks/Nottingham/train', longest_sequence_length=None)\n\ntrainset_loader = data.DataLoader(trainset, batch_size=8,shuffle=True, drop_last=True)","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:21:07.678124Z","start_time":"2018-11-27T12:20:56.931002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valset = NotesGenerationDataset('./Music-Generation/notebooks/Nottingham/valid', longest_sequence_length=None)\n\nvalset_loader = data.DataLoader(valset, batch_size=8, shuffle=False, drop_last=False)","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:21:11.258476Z","start_time":"2018-11-27T12:21:08.259258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val = next(iter(valset_loader))\nX_val[0].shape","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:21:11.406325Z","start_time":"2018-11-27T12:21:11.278687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef note_sampler(loader):\n    X = next(iter(loader))\n    input_sequences_batch, output_sequences_batch, sequences_lengths = post_process_sequence_batch(X)\n    sampled_note = input_sequences_batch[np.random.randint(0,input_sequences_batch.shape[0]),np.random.randint(0,input_sequences_batch.shape[1]),:].view(1,1,-1)\n    return sampled_note.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RNN","metadata":{}},{"cell_type":"code","source":"class RNN(nn.Module):\n    \n    def __init__(self, input_size, hidden_size, num_classes, n_layers=2):\n        \n        super(RNN, self).__init__()\n        \n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_classes = num_classes\n        self.n_layers = n_layers\n        \n        self.notes_encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n        \n        self.bn = nn.BatchNorm1d(hidden_size)\n        \n        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n        \n        self.logits_fc = nn.Linear(hidden_size, num_classes)\n    \n    \n    def forward(self, input_sequences, input_sequences_lengths, hidden=None):\n        batch_size = input_sequences.shape[1]\n\n        notes_encoded = self.notes_encoder(input_sequences)\n        \n        notes_encoded_rolled = notes_encoded.permute(1,2,0).contiguous()\n        notes_encoded_norm = self.bn(notes_encoded_rolled)\n        \n        notes_encoded_norm_drop = nn.Dropout(0.25)(notes_encoded_norm)\n        notes_encoded_complete = notes_encoded_norm_drop.permute(2,0,1)\n        \n        # Here we run rnns only on non-padded regions of the batch\n        #print(notes_encoded_complete.shape)\n        packed = torch.nn.utils.rnn.pack_padded_sequence(notes_encoded_complete, input_sequences_lengths)\n        outputs, hidden = self.lstm(packed, hidden)\n        \n        # Here we unpack sequence(back to padded)\n        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n        \n        outputs_norm = self.bn(outputs.permute(1,2,0).contiguous())\n        outputs_drop = nn.Dropout(0.1)(outputs_norm)\n        logits = self.logits_fc(outputs_drop.permute(2,0,1))\n        logits = logits.transpose(0, 1).contiguous()\n        \n        neg_logits = (1 - logits)\n        \n        # Since the BCE loss doesn't support masking,crossentropy is used\n        binary_logits = torch.stack((logits, neg_logits), dim=3).contiguous()\n        logits_flatten = binary_logits.view(-1, 2)\n        return logits_flatten, hidden","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:22:33.314323Z","start_time":"2018-11-27T12:22:33.291386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RNN(input_size=88, hidden_size=512, num_classes=88).cuda()\n\ncriterion = nn.CrossEntropyLoss().cuda()\ncriterion_val = nn.CrossEntropyLoss().cuda()","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:22:57.954631Z","start_time":"2018-11-27T12:22:36.786295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(model):\n    model.eval()\n    full_val_loss = 0.0\n    overall_sequence_length = 0.0\n\n    for batch in valset_loader:\n        post_processed_batch_tuple = post_process_sequence_batch(batch)\n\n        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n        #print(\"---\")\n        #print(input_sequences_batch.shape, output_sequences_batch.shape, sequences_lengths)\n\n        output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n        #print(output_sequences_batch_var.unique())\n\n        input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n        \n        logits, _ = model(input_sequences_batch_var, sequences_lengths)\n        \n        loss = criterion_val(logits, output_sequences_batch_var)\n\n        full_val_loss += loss.item()\n        overall_sequence_length += sum(sequences_lengths)\n\n    return full_val_loss / (overall_sequence_length * 88)","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:22:58.002722Z","start_time":"2018-11-27T12:22:57.987764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validate(model)","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:23:12.210378Z","start_time":"2018-11-27T12:22:58.040622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clip = 1.0\nepochs_number = 10\nsample_history = []\nbest_val_loss = float(\"inf\")","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:23:12.255258Z","start_time":"2018-11-27T12:23:12.244288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lrfinder(start, end, model, trainset_loader, epochs=2):\n    model.train() # into training mode\n    lrs = np.linspace(start, end, epochs*len(trainset_loader))\n    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n    optimizer = torch.optim.Adam(rnn.parameters(),start)\n    loss_list = []\n    ctr = 0\n    \n    for epoch_number in range(epochs):\n        epoch_loss = []\n        for batch in trainset_loader:\n            optimizer.param_groups[0]['lr'] = lrs[ctr]\n            ctr = ctr+1\n\n            post_processed_batch_tuple = post_process_sequence_batch(batch)\n\n            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n\n            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n\n            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n\n            optimizer.zero_grad()\n\n            logits, _ = model(input_sequences_batch_var, sequences_lengths)\n\n            loss = criterion(logits, output_sequences_batch_var)\n            loss_list.append(loss.item())\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n\n            optimizer.step()\n        print('Epoch %d' % epoch_number)\n    plt.plot(lrs, loss_list)\n    return lrs, loss_list","metadata":{"ExecuteTime":{"end_time":"2018-11-27T12:23:18.442825Z","start_time":"2018-11-27T12:23:18.430860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\nrnn = rnn.cuda()\nlrs, losses = lrfinder(1e-4, 1e-1*5, rnn, trainset_loader)","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:13:45.182544Z","start_time":"2018-11-26T16:11:13.582351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(lrs[:15], losses[:15])","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:16:14.159868Z","start_time":"2018-11-26T16:16:13.950619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_triangular_lr(lr_low, lr_high, mini_batches):\n    iterations = mini_batches\n    lr_mid = lr_high/7 + lr_low\n    up = np.linspace(lr_low, lr_high, int(round(iterations*0.35)))\n    down = np.linspace(lr_high, lr_mid, int(round(iterations*0.35)))\n    floor = np.linspace(lr_mid, lr_low, int(round(iterations*0.30)))\n    return np.hstack([up, down[1:], floor])\n\nlrs_triangular = get_triangular_lr(1e-2, 1e-2*3.5, len(trainset_loader))\nplt.plot(lrs_triangular)","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:16:15.631943Z","start_time":"2018-11-26T16:16:15.434830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clip = 1.0","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:16:17.208992Z","start_time":"2018-11-26T16:16:17.204006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, lrs_triangular, epochs_number=2, wd=0.0, best_val_loss=float(\"inf\")):\n    loss_list = []\n    val_list =[]\n    optimizer = torch.optim.Adam(rnn.parameters(), lr=lrs_triangular[0], weight_decay=wd)\n    for epoch_number in range(epochs_number):\n        model.train()\n        epoch_loss = []\n        for lr, batch in zip(lrs_triangular, trainset_loader):\n            optimizer.param_groups[0]['lr'] = lr\n\n            post_processed_batch_tuple = post_process_sequence_batch(batch)\n\n            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n\n            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n\n            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n\n            optimizer.zero_grad()\n\n            logits, _ = model(input_sequences_batch_var, sequences_lengths)\n\n            loss = criterion(logits, output_sequences_batch_var)\n            loss_list.append(loss.item())\n            epoch_loss.append(loss.item())\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n\n            optimizer.step()\n\n        current_trn_epoch = sum(epoch_loss)/len(trainset_loader)\n        print('Training Loss: Epoch:',epoch_number,':', current_trn_epoch)\n\n        current_val_loss = validate(model)\n        print('Validation Loss: Epoch:',epoch_number,':', current_val_loss)\n        print('')\n\n        val_list.append(current_val_loss)\n\n        if current_val_loss < best_val_loss:\n\n            torch.save(model.state_dict(), 'music_model_padfront_regularized.pth')\n            best_val_loss = current_val_loss\n    return best_val_loss, val_list, loss_list","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:16:18.949227Z","start_time":"2018-11-26T16:16:18.930281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_train_loss = list()\ntotal_val_loss = list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\nrnn = rnn.cuda()\nlrs_triangular = get_triangular_lr(1e-2, 1e-2*3.5, len(trainset_loader))\nbest_val_loss, val_loss, train_loss = train_model(rnn, lrs_triangular)\ntotal_val_loss += val_loss\ntotal_train_loss += train_loss","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:19:05.465667Z","start_time":"2018-11-26T16:16:20.312589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrs_triangular = get_triangular_lr(1e-3, 1e-2, len(trainset_loader))\nbest_val_loss, val_loss, train_loss = train_model(rnn, lrs_triangular, epochs_number=2, wd=1e-4, best_val_loss=best_val_loss)\ntotal_val_loss += val_loss\ntotal_train_loss += train_loss","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:21:52.147229Z","start_time":"2018-11-26T16:19:05.617260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrs_triangular = get_triangular_lr(1e-4, 1e-2, len(trainset_loader))\nbest_val_loss, val_loss, train_loss = train_model(rnn, lrs_triangular, epochs_number=6, wd=1e-4*5, best_val_loss=best_val_loss)\ntotal_val_loss += val_loss\ntotal_train_loss += train_loss","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:24:39.239756Z","start_time":"2018-11-26T16:21:52.289423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rnn.load_state_dict(torch.load('./music_model_padfront_regularized.pth'))","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:15:52.123518Z","start_time":"2018-11-26T16:11:03.940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"def sample_from_piano_rnn(rnn, sample_length=4, temperature=1, starting_sequence=None):\n\n    if starting_sequence is None:\n                \n        current_sequence_input = torch.zeros(1, 1, 88)\n        current_sequence_input[0, 0, 40] = 1\n        current_sequence_input[0, 0, 50] = 0\n        current_sequence_input[0, 0, 56] = 0\n        current_sequence_input = Variable(current_sequence_input.cuda())\n    else:\n        current_sequence_input = starting_sequence\n        \n    final_output_sequence = [current_sequence_input.data.squeeze(1)]\n\n    hidden = None\n\n    for i in range(sample_length):\n\n        output, hidden = rnn(current_sequence_input, [1], hidden)\n        \n        probabilities = nn.functional.softmax(output.div(temperature), dim=1)\n\n        current_sequence_input = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n\n        current_sequence_input = Variable(current_sequence_input.float())\n\n        final_output_sequence.append(current_sequence_input.data.squeeze(1))\n\n    sampled_sequence = torch.cat(final_output_sequence, dim=0).cpu().numpy()\n    \n    return sampled_sequence","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:25:11.202962Z","start_time":"2018-11-26T16:25:11.189993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = sample_from_piano_rnn(rnn, sample_length=200, temperature=0.7,starting_sequence=None).transpose()\nio.imshow(sample)\nmidiwrite('sample_lstm_orig.mid', sample.transpose(), dt=0.3)","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:25:36.632928Z","start_time":"2018-11-26T16:25:34.966547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset = NotesGenerationDataset('./Music-Generation/notebooks/Nottingham/test/', longest_sequence_length=None)\n\ntestset_loader = torch.utils.data.DataLoader(testset, batch_size=1,shuffle=True, drop_last=False)","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:25:16.419484Z","start_time":"2018-11-26T16:25:14.709507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(testset_loader))\npost_processed_batch_tuple = post_process_sequence_batch(batch)\n\ninput_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n\noutput_sequences_batch_var =  output_sequences_batch.contiguous().view(-1).cuda()\n\ninput_sequences_batch_var = input_sequences_batch.cuda()\ninput_sequences_batch_var.shape","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:25:18.156725Z","start_time":"2018-11-26T16:25:17.906750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(input_sequences_batch_var.cpu().reshape((input_sequences_batch_var.shape[0],88)).transpose(0,1))","metadata":{"ExecuteTime":{"end_time":"2018-11-26T16:25:33.195424Z","start_time":"2018-11-26T16:25:32.923613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Note : Please convert the midi file to .mp3 or .wav format to listen","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/BlinkDL/RWKV-LM.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# doing this cahnge is this way since the RWKV path is a submodule\n\n#!cat /kaggle/working/RWKV-LM/RWKV-v4neo/src/model.py | grep Embedding\n#!sed -i 's/Embedding/Linear/g' /kaggle/working/RWKV-LM/RWKV-v4neo/src/model.py\n!sed -i 's/B, T = idx.size/B, T, _ = idx.size/g' /kaggle/working/RWKV-LM/RWKV-v4neo/src/model.py\n#!cat /kaggle/working/RWKV-LM/RWKV-v4neo/src/model.py | grep Embedding\n!cat /kaggle/working/RWKV-LM/RWKV-v4neo/src/model.py | grep \"= idx.size\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append('/kaggle/working/RWKV-LM/RWKV-v4neo')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /kaggle/working/RWKV-LM/RWKV-v4neo/cuda .","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnp.set_printoptions(precision=4, suppress=True, linewidth=200)\nimport types, torch\n\nargs = types.SimpleNamespace()\nargs.n_layer = 6\nargs.n_embd = 512\nargs.vocab_size = 88\nargs.my_pos_emb = 0\nargs.pre_ffn = 0\nargs.ctx_len = 2048\nargs.head_qk = 0\nargs.grad_cp = 0\nargs.gradient_clip_val = 1.0\nargs.magic_prime = 324331313\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"RWKV_JIT_ON\"] = \"1\"\nos.environ[\"RWKV_T_MAX\"] = str(args.ctx_len)\nos.environ[\"RWKV_MY_TESTING\"] = \"\"\nos.environ[\"RWKV_FLOAT_MODE\"] = \"fp16\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from src.model import RWKV\n\nclass RNN_RWKV(nn.Module):\n\n    def __init__(self, args):\n        super(RNN_RWKV, self).__init__()\n        \n        self.rwkv = RWKV(args).cuda()\n        self.rwkv.emb = nn.Linear(args.vocab_size, args.n_embd)\n    \n    def forward(self, input_sequences):\n        logits = self.rwkv(input_sequences)\n        neg_logits = (1 - logits)\n        \n        # Since the BCE loss doesn't support masking,crossentropy is used\n        binary_logits = torch.stack((logits, neg_logits), dim=3).contiguous()\n        logits_flatten = binary_logits.view(-1, 2)\n        return logits_flatten\n\nrnn_rwkv = RNN_RWKV(args).cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rnn_rwkv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate_rnn(model):\n    model.eval()\n    full_val_loss = 0.0\n    overall_sequence_length = 0.0\n\n    for batch in valset_loader:\n        \n        post_processed_batch_tuple = post_process_sequence_batch(batch)\n\n        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n\n        output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n\n        input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n        \n        logits = model(input_sequences_batch_var.permute(1,0,2).cuda())\n        \n        loss = criterion_val(logits, output_sequences_batch_var)\n        #print(loss.item())\n        full_val_loss += loss.item()\n        overall_sequence_length += sum(sequences_lengths)\n\n    return full_val_loss / (overall_sequence_length * 88)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validate_rnn(rnn_rwkv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_rnn_model(model, lrs_triangular, epochs_number=2, wd=0.0, best_val_loss=float(\"inf\")):\n    loss_list = []\n    val_list =[]\n    optimizer = torch.optim.Adam(model.parameters(), lr=lrs_triangular[0], weight_decay=wd)\n    for epoch_number in range(epochs_number):\n        model.train()\n        epoch_loss = []\n        for lr, batch in zip(lrs_triangular, trainset_loader):\n            optimizer.param_groups[0]['lr'] = lr\n\n            post_processed_batch_tuple = post_process_sequence_batch(batch)\n\n            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n\n            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n\n            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n\n            optimizer.zero_grad()\n            \n            logits = model(input_sequences_batch_var.permute(1,0,2).cuda())\n\n            loss = criterion_val(logits, output_sequences_batch_var)\n            loss_list.append(loss.item())\n            epoch_loss.append(loss.item())\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n\n            optimizer.step()\n\n        current_trn_epoch = sum(epoch_loss)/len(trainset_loader)\n        print('Training Loss: Epoch:',epoch_number,':', current_trn_epoch)\n\n        current_val_loss = validate_rnn(model)\n        print('Validation Loss: Epoch:',epoch_number,':', current_val_loss)\n        print('')\n\n        val_list.append(current_val_loss)\n\n        if current_val_loss < best_val_loss:\n\n            torch.save(model.state_dict(), 'music_model_padfront_regularized_rwkv.pth')\n            best_val_loss = current_val_loss\n    return best_val_loss, val_list, loss_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_train_loss_rwkv = list()\ntotal_val_loss_rwkv = list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrs_triangular = get_triangular_lr(1e-2, 1e-2*3.5, len(trainset_loader))\nbest_val_loss, val_loss, train_loss = train_rnn_model(rnn_rwkv, lrs_triangular)\ntotal_val_loss_rwkv += val_loss\ntotal_train_loss_rwkv += train_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrs_triangular = get_triangular_lr(1e-3, 1e-2, len(trainset_loader))\nbest_val_loss, val_loss, train_loss = train_rnn_model(rnn_rwkv, lrs_triangular, epochs_number=2, wd=1e-4, best_val_loss=best_val_loss)\ntotal_val_loss_rwkv += val_loss\ntotal_train_loss_rwkv += train_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrs_triangular = get_triangular_lr(1e-4, 5*1e-4, len(trainset_loader))\nbest_val_loss, val_loss, train_loss = train_rnn_model(rnn_rwkv, lrs_triangular,epochs_number= 2, wd=1e-4*5, best_val_loss=best_val_loss)\ntotal_val_loss_rwkv += val_loss\ntotal_train_loss_rwkv += train_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#optional - may overfit\nlrs_triangular = get_triangular_lr(1e-4, 5*1e-4, len(trainset_loader))\nbest_val_loss = train_rnn_model(rnn_rwkv, lrs_triangular,epochs_number= 10, best_val_loss=best_val_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sample_from_piano_rnn_rwkv(rnn_rwkv, sample_length=4, temperature=1, starting_sequence=None):\n\n    if starting_sequence is None:\n                \n        current_sequence_input = torch.zeros(1, 1, 88)\n        current_sequence_input[0, 0, 40] = 1\n        current_sequence_input[0, 0, 50] = 0\n        current_sequence_input[0, 0, 56] = 0\n        current_sequence_input = Variable(current_sequence_input.cuda())\n    else:\n        current_sequence_input = starting_sequence\n        \n    final_output_sequence = [current_sequence_input.data.squeeze(1)]\n\n    for i in range(sample_length):\n\n        output = rnn_rwkv(current_sequence_input)\n\n        probabilities = nn.functional.softmax(output.div(temperature), dim=1)\n        \n        current_sequence_input = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n\n        current_sequence_input = Variable(current_sequence_input.float())\n\n        final_output_sequence.append(current_sequence_input.data.squeeze(1))\n\n    sampled_sequence = torch.cat(final_output_sequence, dim=0).cpu().numpy()\n    \n    return sampled_sequence","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampled_note = note_sampler(trainset_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = sample_from_piano_rnn_rwkv(rnn_rwkv, sample_length=200, temperature=0.7,starting_sequence=None).transpose()\nio.imshow(sample)\nmidiwrite('sampled_rwkv.mid', sample.transpose(), dt=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = range(1, len(total_val_loss_rwkv) + 1)\n    \nplt.plot(epochs, total_val_loss_rwkv, 'b', label='RWKV Model Validation Loss')\nplt.plot(epochs, total_val_loss, 'r', label='LSTM Model Validation Loss')\nplt.title('Total Validation Loss Comparison')\nplt.xlabel('Epochs')\nplt.ylabel('Total Validation Loss')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batches = range(len(total_train_loss_rwkv))\nplt.plot(batches, total_train_loss_rwkv, 'b', label='RWKV Model Train Loss')\nplt.plot(batches, total_train_loss, 'r', label='LSTM Model Train Loss')\nplt.title('Total Train Loss Comparison')\nplt.xlabel('Batch')\nplt.ylabel('Total Train Loss')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}